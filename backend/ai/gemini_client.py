# -*- coding: utf-8 -*-
"""
Gemini AI í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆ

ğŸ¤” ì´ íŒŒì¼ì´ í•˜ëŠ” ì¼:
ì´ íŒŒì¼ì€ êµ¬ê¸€ì˜ Gemini AIì™€ ëŒ€í™”í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” "ë²ˆì—­ê¸°" ê°™ì€ ì—­í• ì„ í•©ë‹ˆë‹¤.
ìš°ë¦¬ê°€ ê³µì§€ì‚¬í•­ í…ìŠ¤íŠ¸ë¥¼ ì£¼ë©´, Geminiì—ê²Œ ë¬¼ì–´ë³´ê³  ë‹µë³€ì„ ë°›ì•„ì˜¤ëŠ” ì¼ì„ í•©ë‹ˆë‹¤.

ğŸ“š ë¹„ìœ :
- ìš°ë¦¬ = í•œêµ­ì–´ë§Œ í•˜ëŠ” í•™ìƒ
- Gemini AI = ì˜ì–´ë§Œ í•˜ëŠ” ë˜‘ë˜‘í•œ ì„ ìƒë‹˜
- ì´ íŒŒì¼ = í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ, ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ í†µì—­í•´ì£¼ëŠ” í†µì—­ì‚¬
"""

import google.generativeai as genai
import os
from typing import Optional, Dict, Any
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°)
load_dotenv()


class GeminiClient:
    """
    Gemini AIì™€ í†µì‹ í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤

    ğŸ¯ ëª©ì :
    êµ¬ê¸€ Gemini AIì—ê²Œ ì§ˆë¬¸ì„ ë³´ë‚´ê³  ë‹µë³€ì„ ë°›ì•„ì˜¤ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

    ğŸ—ï¸ êµ¬ì¡°:
    1. __init__: Gemini AIì™€ ì—°ê²° ì¤€ë¹„ (ì „í™”ê¸° ì¼œê¸°)
    2. generate_text: í…ìŠ¤íŠ¸ë¥¼ ë³´ë‚´ê³  ë‹µë³€ ë°›ê¸° (ë¬¸ì ë³´ë‚´ê¸°)
    3. analyze_with_prompt: íŠ¹ì • ì§ˆë¬¸ìœ¼ë¡œ ë¶„ì„í•˜ê¸° (íŠ¹ì • ì£¼ì œë¡œ ì§ˆë¬¸í•˜ê¸°)
    """

    def __init__(self, api_key: Optional[str] = None):
        """
        Gemini í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        ğŸ”§ ë§¤ê°œë³€ìˆ˜:
        - api_key: Gemini API í‚¤ (ì—†ìœ¼ë©´ .env íŒŒì¼ì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜´)

        ğŸ’¡ ì˜ˆì‹œ:
        client = GeminiClient()  # .envì—ì„œ ìë™ìœ¼ë¡œ í‚¤ ê°€ì ¸ì˜´
        ë˜ëŠ”
        client = GeminiClient(api_key="ë‚´_API_í‚¤")  # ì§ì ‘ í‚¤ ì „ë‹¬

        ğŸ¯ í•˜ëŠ” ì¼:
        1. API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ (ì§ì ‘ ì£¼ê±°ë‚˜, .envì—ì„œ ìë™ìœ¼ë¡œ)
        2. Geminiì— ì—°ê²°í•©ë‹ˆë‹¤
        3. ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì¤€ë¹„í•©ë‹ˆë‹¤ (gemini-1.5-pro ë˜ëŠ” gemini-1.5-flash)
        """
        # API í‚¤ ì„¤ì •: íŒŒë¼ë¯¸í„°ë¡œ ë°›ì•˜ìœ¼ë©´ ê·¸ê±¸ ì“°ê³ , ì•„ë‹ˆë©´ .envì—ì„œ ê°€ì ¸ì˜´
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')

        # API í‚¤ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°œìƒ
        if not self.api_key:
            raise ValueError(
                "âŒ Gemini API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤! "
                ".env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ "
                "GeminiClient(api_key='your-key')ë¡œ ì§ì ‘ ì „ë‹¬í•˜ì„¸ìš”."
            )

        # Gemini AI ì„¤ì • (API í‚¤ë¡œ ì¸ì¦)
        genai.configure(api_key=self.api_key)

        # ì‚¬ìš©í•  AI ëª¨ë¸ ì„¤ì •
        # gemini-2.5-pro: ìµœì‹  ê³ ì„±ëŠ¥ ëª¨ë¸
        # gemini-2.0-flash: ë¹ ë¥´ê³  íš¨ìœ¨ì , ê°„ë‹¨í•œ ì‘ì—…ìš© (ê¶Œì¥)
        self.model_name = "models/gemini-2.0-flash"  # 2024ë…„ ìµœì‹  ëª¨ë¸
        self.model = genai.GenerativeModel(self.model_name)

        print(f"âœ… Gemini AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {self.model_name})")

    def generate_text(
        self,
        prompt: str,
        max_tokens: int = 2048,
        temperature: float = 0.7
    ) -> str:
        """
        Gemini AIì—ê²Œ í…ìŠ¤íŠ¸ë¥¼ ë³´ë‚´ê³  ë‹µë³€ì„ ë°›ìŠµë‹ˆë‹¤.

        ğŸ”§ ë§¤ê°œë³€ìˆ˜:
        - prompt: Geminiì—ê²Œ ë³´ë‚¼ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ (ì˜ˆ: "ì´ ê³µì§€ì‚¬í•­ ìš”ì•½í•´ì¤˜")
        - max_tokens: ìµœëŒ€ ë‹µë³€ ê¸¸ì´ (ìˆ«ìê°€ í´ìˆ˜ë¡ ê¸´ ë‹µë³€, ê¸°ë³¸ê°’: 2048)
        - temperature: ì°½ì˜ì„± ìˆ˜ì¤€ (0~1, ë†’ì„ìˆ˜ë¡ ì°½ì˜ì /ëœë¤, ê¸°ë³¸ê°’: 0.7)

        ğŸ¯ í•˜ëŠ” ì¼:
        1. ìš°ë¦¬ê°€ ì¤€ ì§ˆë¬¸(prompt)ì„ Geminiì—ê²Œ ë³´ëƒ…ë‹ˆë‹¤
        2. Geminiê°€ ìƒê°í•´ì„œ ë‹µë³€ì„ ë³´ëƒ…ë‹ˆë‹¤
        3. ê·¸ ë‹µë³€ì„ í…ìŠ¤íŠ¸ë¡œ ëŒë ¤ì¤ë‹ˆë‹¤

        ğŸ’¡ ì˜ˆì‹œ:
        ë‹µë³€ = client.generate_text("ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?")
        print(ë‹µë³€)  # Geminiì˜ ë‹µë³€ì´ ì¶œë ¥ë¨

        ğŸ“Œ Temperatureë€?
        - 0.0: í•­ìƒ ë˜‘ê°™ì€ ë‹µë³€ (ë¡œë´‡ì²˜ëŸ¼)
        - 0.5: ì ë‹¹íˆ ì¼ê´€ì 
        - 1.0: ë§¤ë²ˆ ë‹¤ë¥¸ ì°½ì˜ì  ë‹µë³€
        """
        try:
            # Geminiì—ê²Œ ì§ˆë¬¸ ë³´ë‚´ê¸°
            response = self.model.generate_content(
                prompt,
                generation_config={
                    "max_output_tokens": max_tokens,  # ìµœëŒ€ ë‹µë³€ ê¸¸ì´
                    "temperature": temperature,  # ì°½ì˜ì„± ìˆ˜ì¤€
                }
            )

            # ë‹µë³€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            return response.text

        except Exception as e:
            # ì—ëŸ¬ ë°œìƒ ì‹œ ì–´ë–¤ ì—ëŸ¬ì¸ì§€ ì•Œë ¤ì¤Œ
            raise Exception(f"âŒ Gemini AI í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")

    def analyze_with_prompt(
        self,
        content: str,
        analysis_type: str = "summary"
    ) -> Dict[str, Any]:
        """
        íŠ¹ì • ëª©ì ì— ë§ê²Œ ê³µì§€ì‚¬í•­ì„ ë¶„ì„í•©ë‹ˆë‹¤.

        ğŸ”§ ë§¤ê°œë³€ìˆ˜:
        - content: ë¶„ì„í•  ê³µì§€ì‚¬í•­ ë‚´ìš©
        - analysis_type: ë¶„ì„ ì¢…ë¥˜
          * "summary": ìš”ì•½ (ê¸´ ê¸€ì„ ì§§ê²Œ)
          * "schedule": ì¼ì • ì¶”ì¶œ (ë‚ ì§œ, ì‹œê°„ ì°¾ê¸°)
          * "category": ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (í•™ì‚¬/ì¥í•™/ì·¨ì—… ë“±)
          * "importance": ì¤‘ìš”ë„ íŒë‹¨ (ë³„ 1ê°œ~5ê°œ)

        ğŸ¯ í•˜ëŠ” ì¼:
        1. ë¶„ì„ ì¢…ë¥˜ì— ë§ëŠ” ì§ˆë¬¸ì„ ë§Œë“­ë‹ˆë‹¤
        2. Geminiì—ê²Œ ê·¸ ì§ˆë¬¸ê³¼ í•¨ê»˜ ê³µì§€ì‚¬í•­ì„ ë³´ëƒ…ë‹ˆë‹¤
        3. Geminiì˜ ë‹µë³€ì„ ì •ë¦¬í•´ì„œ ëŒë ¤ì¤ë‹ˆë‹¤

        ğŸ’¡ ì˜ˆì‹œ:
        result = client.analyze_with_prompt(
            content="2024ë…„ 1í•™ê¸° ìˆ˜ê°•ì‹ ì²­ì€ 2ì›” 1ì¼ë¶€í„°ì…ë‹ˆë‹¤.",
            analysis_type="schedule"
        )
        print(result)
        # {"analysis_type": "schedule", "result": "ìˆ˜ê°•ì‹ ì²­: 2024-02-01"}
        """

        # ë¶„ì„ ì¢…ë¥˜ë³„ í”„ë¡¬í”„íŠ¸(ì§ˆë¬¸) í…œí”Œë¦¿
        prompts = {
            "summary": f"""
                ë‹¤ìŒ ê³µì§€ì‚¬í•­ì„ 3ì¤„ ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
                ì¤‘ìš”í•œ ë‚´ìš©ë§Œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

                ê³µì§€ì‚¬í•­:
                {content}

                ìš”ì•½:
            """,

            "schedule": f"""
                ë‹¤ìŒ ê³µì§€ì‚¬í•­ì—ì„œ ë‚ ì§œì™€ ì¼ì • ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
                í˜•ì‹: YYYY-MM-DD HH:MM ë˜ëŠ” YYYY-MM-DD
                ë‚ ì§œê°€ ì—†ìœ¼ë©´ "ì¼ì • ì—†ìŒ"ì´ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”.

                ê³µì§€ì‚¬í•­:
                {content}

                ì¼ì •:
            """,

            "category": f"""
                ë‹¤ìŒ ê³µì§€ì‚¬í•­ì„ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.
                ì¹´í…Œê³ ë¦¬ ì¢…ë¥˜: í•™ì‚¬, ì¥í•™, ì·¨ì—…, í–‰ì‚¬, ê¸°íƒ€
                ì¹´í…Œê³ ë¦¬ ì´ë¦„ë§Œ ë‹µí•´ì£¼ì„¸ìš”.

                ê³µì§€ì‚¬í•­:
                {content}

                ì¹´í…Œê³ ë¦¬:
            """,

            "importance": f"""
                ë‹¤ìŒ ê³µì§€ì‚¬í•­ì˜ ì¤‘ìš”ë„ë¥¼ 1~5ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.
                1ì : ë³„ë¡œ ì•ˆ ì¤‘ìš”í•¨
                5ì : ë§¤ìš° ì¤‘ìš”í•¨ (í•„ë…)

                ì ìˆ˜ë§Œ ìˆ«ìë¡œ ë‹µí•´ì£¼ì„¸ìš”.

                ê³µì§€ì‚¬í•­:
                {content}

                ì¤‘ìš”ë„ ì ìˆ˜:
            """
        }

        # ì„ íƒí•œ ë¶„ì„ ì¢…ë¥˜ì˜ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        if analysis_type not in prompts:
            raise ValueError(
                f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶„ì„ íƒ€ì…: {analysis_type}\n"
                f"ì‚¬ìš© ê°€ëŠ¥í•œ íƒ€ì…: {', '.join(prompts.keys())}"
            )

        prompt = prompts[analysis_type]

        # Geminiì—ê²Œ ë¶„ì„ ìš”ì²­
        result = self.generate_text(prompt, temperature=0.3)  # ì¼ê´€ëœ ë‹µë³€ì„ ìœ„í•´ ë‚®ì€ temperature

        # ê²°ê³¼ë¥¼ ì‚¬ì „ í˜•íƒœë¡œ ì •ë¦¬
        return {
            "analysis_type": analysis_type,
            "result": result.strip(),  # ì•ë’¤ ê³µë°± ì œê±°
            "original_content": content
        }

    def switch_model(self, model_name: str):
        """
        ì‚¬ìš©í•  Gemini ëª¨ë¸ì„ ë³€ê²½í•©ë‹ˆë‹¤.

        ğŸ”§ ë§¤ê°œë³€ìˆ˜:
        - model_name: ë³€ê²½í•  ëª¨ë¸ ì´ë¦„
          * "gemini-1.5-pro": ë˜‘ë˜‘í•˜ì§€ë§Œ ëŠë¦¼
          * "gemini-1.5-flash": ë¹ ë¥´ì§€ë§Œ ëœ ë˜‘ë˜‘í•¨

        ğŸ’¡ ì˜ˆì‹œ:
        client.switch_model("gemini-1.5-pro")  # ë³µì¡í•œ ë¶„ì„í•  ë•Œ
        client.switch_model("gemini-1.5-flash")  # ë¹ ë¥¸ ì²˜ë¦¬ í•„ìš”í•  ë•Œ
        """
        self.model_name = model_name
        self.model = genai.GenerativeModel(self.model_name)
        print(f"âœ… ëª¨ë¸ ë³€ê²½ë¨: {self.model_name}")


# ğŸ§ª í…ŒìŠ¤íŠ¸ ì½”ë“œ (ì´ íŒŒì¼ì„ ì§ì ‘ ì‹¤í–‰í–ˆì„ ë•Œë§Œ ì‘ë™)
if __name__ == "__main__":
    print("=" * 50)
    print("ğŸ§ª Gemini í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)

    try:
        # 1. í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        print("\n[1ë‹¨ê³„] Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
        client = GeminiClient()

        # 2. ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
        print("\n[2ë‹¨ê³„] ê°„ë‹¨í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸...")
        response = client.generate_text("ì•ˆë…•í•˜ì„¸ìš”! ê°„ë‹¨íˆ ì¸ì‚¬í•´ì£¼ì„¸ìš”.")
        print(f"âœ… Gemini ì‘ë‹µ: {response}")

        # 3. ê³µì§€ì‚¬í•­ ë¶„ì„ í…ŒìŠ¤íŠ¸
        print("\n[3ë‹¨ê³„] ê³µì§€ì‚¬í•­ ë¶„ì„ í…ŒìŠ¤íŠ¸...")
        test_notice = """
        [í•™ì‚¬ê³µì§€] 2024í•™ë…„ë„ 1í•™ê¸° ìˆ˜ê°•ì‹ ì²­ ì•ˆë‚´

        ìˆ˜ê°•ì‹ ì²­ ì¼ì •:
        - 4í•™ë…„: 2024ë…„ 2ì›” 1ì¼ 10:00 ~ 2ì›” 2ì¼ 18:00
        - 3í•™ë…„: 2024ë…„ 2ì›” 2ì¼ 10:00 ~ 2ì›” 3ì¼ 18:00
        - 2í•™ë…„: 2024ë…„ 2ì›” 3ì¼ 10:00 ~ 2ì›” 4ì¼ 18:00
        - 1í•™ë…„: 2024ë…„ 2ì›” 4ì¼ 10:00 ~ 2ì›” 5ì¼ 18:00

        í•™ìƒì§€ì›ì²˜ í•™ì‚¬ìš´ì˜íŒ€
        """

        # ìš”ì•½ ë¶„ì„
        print("\n  ğŸ“ ìš”ì•½ ë¶„ì„ ì¤‘...")
        summary_result = client.analyze_with_prompt(test_notice, "summary")
        print(f"  âœ… ìš”ì•½: {summary_result['result']}")

        # ì¼ì • ì¶”ì¶œ
        print("\n  ğŸ“… ì¼ì • ì¶”ì¶œ ì¤‘...")
        schedule_result = client.analyze_with_prompt(test_notice, "schedule")
        print(f"  âœ… ì¼ì •: {schedule_result['result']}")

        # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        print("\n  ğŸ·ï¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...")
        category_result = client.analyze_with_prompt(test_notice, "category")
        print(f"  âœ… ì¹´í…Œê³ ë¦¬: {category_result['result']}")

        # ì¤‘ìš”ë„ íŒë‹¨
        print("\n  â­ ì¤‘ìš”ë„ íŒë‹¨ ì¤‘...")
        importance_result = client.analyze_with_prompt(test_notice, "importance")
        print(f"  âœ… ì¤‘ìš”ë„: {importance_result['result']}")

        print("\n" + "=" * 50)
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("=" * 50)

    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
