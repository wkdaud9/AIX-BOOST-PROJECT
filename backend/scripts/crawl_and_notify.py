#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í¬ë¡¤ë§ + AI ë¶„ì„ + ì•Œë¦¼ íŒŒì´í”„ë¼ì¸

ğŸ¤” ì´ íŒŒì¼ì´ í•˜ëŠ” ì¼:
15ë¶„ë§ˆë‹¤ Render Cron Jobì—ì„œ ìë™ ì‹¤í–‰ë˜ëŠ” ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
í¬ë¡¤ë§ â†’ AI ë¶„ì„ â†’ ì‚¬ìš©ìë³„ ê´€ë ¨ë„ ê³„ì‚° â†’ í‘¸ì‹œ ì•Œë¦¼ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

ğŸ“š ì‹¤í–‰ ìˆœì„œ:
1. í¬ë¡¤ëŸ¬ ì‹¤í–‰ (ìƒˆ ê³µì§€ ê°ì§€)
2. AI ì „ì²´ ë¶„ì„ (ìš”ì•½, ì¹´í…Œê³ ë¦¬, ì¤‘ìš”ë„)
3. DB ì €ì¥ (notices í…Œì´ë¸”)
4. ì‚¬ìš©ìë³„ ê´€ë ¨ë„ ê³„ì‚° (ai_analysis í…Œì´ë¸”)
5. í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡ (relevance_score >= 0.5)
6. ì•Œë¦¼ ë¡œê·¸ ì €ì¥ (notification_logs í…Œì´ë¸”)

ğŸ’¡ ì‹¤í–‰ ë°©ë²•:
python backend/scripts/crawl_and_notify.py
"""

import os
import sys
from datetime import datetime
from typing import List, Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from crawler.notice_crawler import NoticeCrawler
from crawler.scholarship_crawler import ScholarshipCrawler
from crawler.recruitment_crawler import RecruitmentCrawler
from ai.analyzer import NoticeAnalyzer
from services.notice_service import NoticeService
from services.ai_analysis_service import AIAnalysisService
from services.calendar_service import CalendarService
from supabase import create_client


class CrawlAndNotifyPipeline:
    """
    í¬ë¡¤ë§ + ë¶„ì„ + ì•Œë¦¼ íŒŒì´í”„ë¼ì¸

    ğŸ¯ ëª©ì :
    ì „ì²´ ìë™í™” í”„ë¡œì„¸ìŠ¤ë¥¼ í•œ ë²ˆì— ì‹¤í–‰í•©ë‹ˆë‹¤.
    """

    def __init__(self):
        """íŒŒì´í”„ë¼ì¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        print("\n" + "="*60)
        print("ğŸš€ í¬ë¡¤ë§ + ë¶„ì„ + ì•Œë¦¼ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print("="*60)

        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.notice_service = NoticeService()
        self.ai_analyzer = NoticeAnalyzer()
        self.ai_analysis_service = AIAnalysisService()
        self.calendar_service = CalendarService()

        # Supabase í´ë¼ì´ì–¸íŠ¸ (ì•Œë¦¼ ë¡œê·¸ìš©)
        self.supabase_url = os.getenv("SUPABASE_URL")
        self.supabase_key = os.getenv("SUPABASE_KEY")
        self.supabase = create_client(self.supabase_url, self.supabase_key)

        # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        self.crawlers = {
            "ê³µì§€ì‚¬í•­": NoticeCrawler(),
            "í•™ì‚¬/ì¥í•™": ScholarshipCrawler(),
            "ëª¨ì§‘ê³µê³ ": RecruitmentCrawler()
        }

        print("âœ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ\n")

    def run(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        start_time = datetime.now()

        try:
            # 1ë‹¨ê³„: í¬ë¡¤ë§
            new_notices = self._step1_crawl()

            if not new_notices:
                print("\nâœ… ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return

            # 2ë‹¨ê³„: AI ë¶„ì„
            analyzed_notices = self._step2_analyze(new_notices)

            # 3ë‹¨ê³„: DB ì €ì¥
            saved_ids = self._step3_save_to_db(analyzed_notices)

            # 4ë‹¨ê³„: ì‚¬ìš©ìë³„ ê´€ë ¨ë„ ê³„ì‚°
            relevance_results = self._step4_calculate_relevance(saved_ids)

            # 5ë‹¨ê³„: ìº˜ë¦°ë” ì´ë²¤íŠ¸ ìƒì„±
            calendar_count = self._step5_create_calendar_events(analyzed_notices)

            # 6ë‹¨ê³„: í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡
            notification_count = self._step6_send_notifications(relevance_results)

            # ìµœì¢… í†µê³„
            self._print_final_stats(
                start_time=start_time,
                new_count=len(new_notices),
                analyzed_count=len(analyzed_notices),
                saved_count=len(saved_ids),
                relevance_count=sum(r['notified'] for r in relevance_results.values()),
                calendar_count=calendar_count,
                notification_count=notification_count
            )

        except Exception as e:
            print(f"\nâŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()

    def _step1_crawl(self) -> List[Dict[str, Any]]:
        """1ë‹¨ê³„: ìƒˆ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§"""
        print("\n" + "â”€"*60)
        print("ğŸ“¡ [1ë‹¨ê³„] ìƒˆ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§")
        print("â”€"*60)

        all_new_notices = []

        for category, crawler in self.crawlers.items():
            print(f"\nğŸ” [{category}] í¬ë¡¤ë§ ì¤‘...")

            # DBì—ì„œ ë§ˆì§€ë§‰ ì €ì¥ëœ ê³µì§€ ID ì¡°íšŒ
            last_id = self.notice_service.get_latest_original_id(category=category)

            # ìµœì í™”ëœ í¬ë¡¤ë§ (ëª©ë¡ ë¨¼ì € í™•ì¸)
            if hasattr(crawler, 'crawl_optimized'):
                new_notices = crawler.crawl_optimized(
                    last_known_id=last_id,
                    max_pages=3  # ìµœëŒ€ 3í˜ì´ì§€ê¹Œì§€ í™•ì¸
                )
            else:
                # ê¸°ì¡´ í¬ë¡¤ëŸ¬ëŠ” ì¼ë°˜ í¬ë¡¤ë§
                new_notices = crawler.crawl(max_pages=1)

            if new_notices:
                print(f"  âœ… {len(new_notices)}ê°œ ìƒˆ ê³µì§€ ë°œê²¬")
                all_new_notices.extend(new_notices)
            else:
                print(f"  â„¹ï¸ ìƒˆ ê³µì§€ ì—†ìŒ")

        print(f"\nğŸ“Š í¬ë¡¤ë§ ì™„ë£Œ: ì´ {len(all_new_notices)}ê°œ ìƒˆ ê³µì§€")
        return all_new_notices

    def _step2_analyze(self, notices: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """2ë‹¨ê³„: AI ì „ì²´ ë¶„ì„"""
        print("\n" + "â”€"*60)
        print("ğŸ¤– [2ë‹¨ê³„] AI ì „ì²´ ë¶„ì„")
        print("â”€"*60)

        analyzed_notices = []

        for i, notice in enumerate(notices, 1):
            title = notice.get('title', '')[:40]
            print(f"\n[{i}/{len(notices)}] {title}...")

            try:
                # AI ì¢…í•© ë¶„ì„ (ìš”ì•½, ì¹´í…Œê³ ë¦¬, ì¤‘ìš”ë„, ë‚ ì§œ)
                analysis = self.ai_analyzer.analyze_notice_comprehensive(notice)
                analyzed_notices.append(analysis)
                print(f"  âœ… ë¶„ì„ ì™„ë£Œ - {analysis.get('category', 'ê¸°íƒ€')}/{analysis.get('priority', 'ì¼ë°˜')}")

            except Exception as e:
                print(f"  âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                # ë¶„ì„ ì‹¤íŒ¨í•´ë„ ì›ë³¸ ë°ì´í„°ëŠ” ìœ ì§€
                notice['analyzed'] = False
                analyzed_notices.append(notice)

        print(f"\nğŸ“Š AI ë¶„ì„ ì™„ë£Œ: {len(analyzed_notices)}ê°œ")
        return analyzed_notices

    def _step3_save_to_db(self, notices: List[Dict[str, Any]]) -> List[str]:
        """3ë‹¨ê³„: DB ì €ì¥"""
        print("\n" + "â”€"*60)
        print("ğŸ’¾ [3ë‹¨ê³„] DB ì €ì¥")
        print("â”€"*60)

        saved_ids = []

        for i, notice in enumerate(notices, 1):
            print(f"\n[{i}/{len(notices)}] ì €ì¥ ì¤‘...")

            notice_id = self.notice_service.save_analyzed_notice(notice)

            if notice_id:
                saved_ids.append(notice_id)

        print(f"\nğŸ“Š DB ì €ì¥ ì™„ë£Œ: {len(saved_ids)}ê°œ")
        return saved_ids

    def _step4_calculate_relevance(
        self,
        notice_ids: List[str]
    ) -> Dict[str, Dict[str, int]]:
        """4ë‹¨ê³„: ì‚¬ìš©ìë³„ ê´€ë ¨ë„ ê³„ì‚°"""
        print("\n" + "â”€"*60)
        print("ğŸ¯ [4ë‹¨ê³„] ì‚¬ìš©ìë³„ ê´€ë ¨ë„ ê³„ì‚°")
        print("â”€"*60)

        relevance_results = {}

        for i, notice_id in enumerate(notice_ids, 1):
            print(f"\n[{i}/{len(notice_ids)}] ê³µì§€ {notice_id[:8]}... ê´€ë ¨ë„ ê³„ì‚° ì¤‘")

            try:
                # ì „ì²´ ì‚¬ìš©ìì— ëŒ€í•´ ê´€ë ¨ë„ ê³„ì‚°
                result = self.ai_analysis_service.batch_analyze_for_users(
                    notice_id=notice_id,
                    user_ids=None  # None = ì „ì²´ ì‚¬ìš©ì
                )

                relevance_results[notice_id] = result
                print(f"  âœ… {result['analyzed']}ëª… ë¶„ì„ ì™„ë£Œ, {result['notified']}ëª… ì•Œë¦¼ ëŒ€ìƒ")

            except Exception as e:
                print(f"  âŒ ê´€ë ¨ë„ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
                relevance_results[notice_id] = {"total": 0, "analyzed": 0, "notified": 0}

        total_notified = sum(r['notified'] for r in relevance_results.values())
        print(f"\nğŸ“Š ê´€ë ¨ë„ ê³„ì‚° ì™„ë£Œ: {len(notice_ids)}ê°œ ê³µì§€, ì´ {total_notified}ê±´ ì•Œë¦¼ ëŒ€ìƒ")

        return relevance_results

    def _step5_create_calendar_events(
        self,
        notices: List[Dict[str, Any]]
    ) -> int:
        """5ë‹¨ê³„: ìº˜ë¦°ë” ì´ë²¤íŠ¸ ìƒì„±"""
        print("\n" + "â”€"*60)
        print("ğŸ“… [5ë‹¨ê³„] ìº˜ë¦°ë” ì´ë²¤íŠ¸ ìƒì„±")
        print("â”€"*60)

        calendar_count = 0

        for i, notice in enumerate(notices, 1):
            dates = notice.get("dates", {})

            # ë‚ ì§œ ì •ë³´ê°€ ìˆëŠ” ê³µì§€ë§Œ ì²˜ë¦¬
            if not dates or not any(dates.values()):
                continue

            print(f"\n[{i}/{len(notices)}] ìº˜ë¦°ë” ì´ë²¤íŠ¸ ìƒì„± ì¤‘...")

            try:
                event_ids = self.calendar_service.create_calendar_events(
                    notice_id=notice.get("id"),
                    dates=dates,
                    notice_title=notice.get("original_title", notice.get("title", "")),
                    category=notice.get("category", "ê¸°íƒ€"),
                    user_ids=None  # ê´€ì‹¬ ì‚¬ìš©ì ìë™ ì¡°íšŒ
                )
                calendar_count += len(event_ids)
                print(f"  âœ… {len(event_ids)}ê°œ ì´ë²¤íŠ¸ ìƒì„±")

            except Exception as e:
                print(f"  âŒ ìº˜ë¦°ë” ìƒì„± ì‹¤íŒ¨: {str(e)}")

        print(f"\nğŸ“Š ìº˜ë¦°ë” ì´ë²¤íŠ¸ ìƒì„± ì™„ë£Œ: {calendar_count}ê°œ")
        return calendar_count

    def _step6_send_notifications(
        self,
        relevance_results: Dict[str, Dict[str, int]]
    ) -> int:
        """6ë‹¨ê³„: í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡"""
        print("\n" + "â”€"*60)
        print("ğŸ”” [6ë‹¨ê³„] í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡")
        print("â”€"*60)

        notification_count = 0

        try:
            # relevance_score >= 0.5ì¸ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
            for notice_id, result in relevance_results.items():
                if result['notified'] == 0:
                    continue

                print(f"\nğŸ“¢ ê³µì§€ {notice_id[:8]}... ì•Œë¦¼ ë°œì†¡ ì¤‘ ({result['notified']}ëª…)")

                # ai_analysis í…Œì´ë¸”ì—ì„œ ì•Œë¦¼ ëŒ€ìƒ ì¡°íšŒ
                analyses = self.supabase.table("ai_analysis")\
                    .select("*, users(id, name, fcm_token), notices(title, category)")\
                    .eq("notice_id", notice_id)\
                    .gte("relevance_score", 0.5)\
                    .execute()

                for analysis in analyses.data:
                    user = analysis.get("users", {})
                    notice = analysis.get("notices", {})
                    fcm_token = user.get("fcm_token")

                    if not fcm_token:
                        print(f"  âš ï¸ {user.get('name', 'Unknown')} - FCM í† í° ì—†ìŒ")
                        continue

                    # TODO: FCM í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡ (ë‚˜ì¤‘ì— êµ¬í˜„)
                    # send_fcm_notification(fcm_token, notice['title'], ...)

                    # ì•Œë¦¼ ë¡œê·¸ ì €ì¥
                    try:
                        self.supabase.table("notification_logs").insert({
                            "user_id": user["id"],
                            "notice_id": notice_id,
                            "type": "push",
                            "title": notice.get("title", ""),
                            "message": analysis.get("summary", ""),
                            "sent_at": datetime.now().isoformat(),
                            "status": "pending"  # FCM êµ¬í˜„ í›„ "sent"ë¡œ ë³€ê²½
                        }).execute()

                        notification_count += 1
                        print(f"  âœ… {user.get('name', 'Unknown')} - ì•Œë¦¼ ëŒ€ê¸° ì¤‘")

                    except Exception as e:
                        print(f"  âŒ ì•Œë¦¼ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

            print(f"\nğŸ“Š ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ: {notification_count}ê±´")
            print("âš ï¸ ì£¼ì˜: FCM ë¯¸êµ¬í˜„ìœ¼ë¡œ ì•Œë¦¼ì´ ì‹¤ì œ ë°œì†¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        except Exception as e:
            print(f"\nâŒ ì•Œë¦¼ ë°œì†¡ ì‹¤íŒ¨: {str(e)}")

        return notification_count

    def _print_final_stats(
        self,
        start_time: datetime,
        new_count: int,
        analyzed_count: int,
        saved_count: int,
        relevance_count: int,
        calendar_count: int,
        notification_count: int
    ):
        """ìµœì¢… í†µê³„ ì¶œë ¥"""
        end_time = datetime.now()
        elapsed = (end_time - start_time).total_seconds()

        print("\n" + "="*60)
        print("âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("="*60)
        print(f"\nğŸ“Š ìµœì¢… í†µê³„:")
        print(f"  - ìƒˆ ê³µì§€ í¬ë¡¤ë§: {new_count}ê°œ")
        print(f"  - AI ë¶„ì„ ì™„ë£Œ: {analyzed_count}ê°œ")
        print(f"  - DB ì €ì¥: {saved_count}ê°œ")
        print(f"  - ê´€ë ¨ë„ ë¶„ì„: {relevance_count}ê±´")
        print(f"  - ìº˜ë¦°ë” ì´ë²¤íŠ¸: {calendar_count}ê°œ")
        print(f"  - ì•Œë¦¼ ë°œì†¡: {notification_count}ê±´")
        print(f"  - ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
        print(f"  - ì™„ë£Œ ì‹œê°: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60 + "\n")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
        from dotenv import load_dotenv
        load_dotenv()

        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline = CrawlAndNotifyPipeline()
        pipeline.run()

    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
