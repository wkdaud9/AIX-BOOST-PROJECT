# -*- coding: utf-8 -*-
"""
ì½˜í…ì¸  Markdown ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ í•˜ëŠ” ì¼:
ê¸°ì¡´ DBì˜ ê³µì§€ì‚¬í•­ contentë¥¼ source_urlì—ì„œ HTMLì„ ë‹¤ì‹œ ê°€ì ¸ì™€
Markdownìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
AI ì¬ë¶„ì„ ì—†ì´ content ì»¬ëŸ¼ë§Œ ê°±ì‹ í•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
    cd backend
    python scripts/migrate_content_to_markdown.py

ì˜µì…˜:
    --dry-run: ì‹¤ì œ ì €ì¥ ì—†ì´ ë³€í™˜ ê²°ê³¼ë§Œ ë¯¸ë¦¬ë³´ê¸°
    --limit N: ìµœëŒ€ Nê°œ ê³µì§€ë§Œ ì²˜ë¦¬
"""

import os
import sys
import re
import time
import random
import argparse
import requests
from bs4 import BeautifulSoup
from markdownify import markdownify as md, MarkdownConverter

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


def clean_markdown(text: str) -> str:
    """
    markdownify ì¶œë ¥ì˜ íŒŒí¸í™”ëœ ì„œì‹ì„ ì •ë¦¬í•©ë‹ˆë‹¤.

    í•™êµ í™ˆí˜ì´ì§€ HTMLì—ì„œ <b>2026</b><b>ë…„</b> ê°™ì´ íƒœê·¸ê°€ íŒŒí¸í™”ë˜ì–´ ìˆìœ¼ë©´
    markdownifyê°€ **2026****ë…„** ìœ¼ë¡œ ë³€í™˜í•˜ë¯€ë¡œ ì´ë¥¼ **2026ë…„** ìœ¼ë¡œ ë³‘í•©í•©ë‹ˆë‹¤.
    """
    # 1. ì—°ì†ëœ bold ë§ˆì»¤ ë³‘í•©: **text****text** â†’ **texttext**
    text = text.replace('****', '')
    # 2. ì¸ì ‘í•œ bold êµ¬ê°„ ë³‘í•©: **text** **text** â†’ **text text**
    text = re.sub(r'\*\*(\s+)\*\*', r'\1', text)
    # 3. ë¹ˆ bold ì œê±°: **  ** â†’ (ë¹ˆ ë¬¸ìì—´)
    text = re.sub(r'\*\*\s*\*\*', '', text)
    # 4. íŠ¹ìˆ˜ë¬¸ì ì£¼ìœ„ íŒŒí¸í™”ëœ bold ì œê±°: **â€»** â†’ â€», **â€§** â†’ â€§
    text = re.sub(r'\*\*([^\w\s])\*\*', r'\1', text)
    # 5. ì§ì´ ë§ì§€ ì•ŠëŠ” bold ë§ˆì»¤ ì œê±° (ì¤„ ë‹¨ìœ„ë¡œ ** ê°œìˆ˜ê°€ í™€ìˆ˜ë©´ ì œê±°)
    lines = text.split('\n')
    fixed_lines = []
    for line in lines:
        if line.count('**') % 2 != 0:
            line = line.replace('**', '')
        fixed_lines.append(line)
    text = '\n'.join(fixed_lines)
    # 6. ì´ìŠ¤ì¼€ì´í”„ëœ asterisk ë³µì›: \* â†’ * (markdownifyê°€ * ë¥¼ \* ë¡œ ì´ìŠ¤ì¼€ì´í”„)
    text = text.replace('\\*', '*')
    # 7. ì—°ì† ë¹ˆ ì¤„ ì •ë¦¬ (3ì¤„ ì´ìƒ â†’ 2ì¤„)
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text.strip()


class AlignPreservingConverter(MarkdownConverter):
    """text-align CSS ì†ì„±ì„ ë§ˆì»¤ë¡œ ë³´ì¡´í•˜ëŠ” Markdown ë³€í™˜ê¸°"""

    def _get_align(self, el):
        """ì—˜ë¦¬ë¨¼íŠ¸ì˜ text-align ì†ì„± í™•ì¸ (CSS style + HTML align ì†ì„±)"""
        style = el.get('style', '') if hasattr(el, 'get') else ''
        align_attr = el.get('align', '') if hasattr(el, 'get') else ''

        if 'text-align' in style:
            match = re.search(r'text-align\s*:\s*(center|right)', style)
            if match:
                return match.group(1)
        if align_attr in ('center', 'right'):
            return align_attr
        return None

    def convert_p(self, el, text, *args, **kwargs):
        """p íƒœê·¸ ë³€í™˜ ì‹œ text-align ë³´ì¡´"""
        result = super().convert_p(el, text, *args, **kwargs)
        align = self._get_align(el)
        if align and result.strip():
            stripped = result.strip()
            result = f'\n\n{{={align}=}}{stripped}{{=/{align}=}}\n\n'
        return result

    def convert_div(self, el, text, *args, **kwargs):
        """div íƒœê·¸ ë³€í™˜ ì‹œ text-align ë³´ì¡´ (í•˜ìœ„ ìš”ì†Œì— ë§ˆì»¤ê°€ ì—†ëŠ” ê²½ìš°ë§Œ)"""
        result = super().convert_div(el, text, *args, **kwargs)
        align = self._get_align(el)
        if align and result.strip() and '{=' not in result:
            lines = result.strip().split('\n')
            marked = []
            for line in lines:
                if line.strip():
                    marked.append(f'{{={align}=}}{line}{{=/{align}=}}')
                else:
                    marked.append(line)
            result = '\n\n' + '\n'.join(marked) + '\n\n'
        return result

    def convert_center(self, el, text, *args, **kwargs):
        """<center> íƒœê·¸ë¥¼ center ë§ˆì»¤ë¡œ ë³€í™˜"""
        if text.strip():
            return f'\n\n{{=center=}}{text.strip()}{{=/center=}}\n\n'
        return text


def md_with_align(html, **kwargs):
    """text-align ë³´ì¡´ Markdown ë³€í™˜ í—¬í¼ í•¨ìˆ˜"""
    return AlignPreservingConverter(**kwargs).convert(html)


from dotenv import load_dotenv
load_dotenv()

from supabase import create_client, Client

# êµ°ì‚°ëŒ€ ê¸°ë³¸ URL
BASE_URL = "https://www.kunsan.ac.kr"


def get_supabase_client() -> Client:
    """Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    url = os.getenv("SUPABASE_URL")
    key = os.getenv("SUPABASE_KEY")
    if not url or not key:
        raise ValueError("SUPABASE_URL, SUPABASE_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
    return create_client(url, key)


def fetch_and_convert(source_url: str, session: requests.Session) -> dict:
    """
    source_urlì—ì„œ HTMLì„ ê°€ì ¸ì™€ Markdownìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    ë°˜í™˜ê°’:
    - {"content": "ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸", "content_images": ["url1", ...]}
    - ì‹¤íŒ¨ ì‹œ None
    """
    try:
        response = session.get(source_url, timeout=10)
        response.raise_for_status()
        response.encoding = 'utf-8'

        soup = BeautifulSoup(response.text, 'html.parser')

        # ë³¸ë¬¸ ìš”ì†Œ ì°¾ê¸° (í¬ë¡¤ëŸ¬ì™€ ë™ì¼í•œ ì…€ë ‰í„°)
        content_elem = (
            soup.select_one('div.bv_content_text') or
            soup.select_one('.board-view-content') or
            soup.select_one('.view-content') or
            soup.select_one('.cont_box')
        )

        if not content_elem:
            return None

        # ì´ë¯¸ì§€ ìƒëŒ€ê²½ë¡œ â†’ ì ˆëŒ€ê²½ë¡œ ë³€í™˜
        for img in content_elem.select('img'):
            src = img.get('src', '')
            if src and not src.startswith('http'):
                img['src'] = BASE_URL + src

        # HTML â†’ Markdown ë³€í™˜ + ì •ë ¬ ë³´ì¡´ + íŒŒí¸í™”ëœ ì„œì‹ ì •ë¦¬
        content_md = clean_markdown(md_with_align(
            str(content_elem),
            heading_style="ATX",
            strip=['script', 'style'],
        ))

        # ì´ë¯¸ì§€ URL ì¶”ì¶œ
        content_images = []
        for img in content_elem.select('img'):
            src = img.get('src', '')
            if src:
                content_images.append(src)

        return {
            "content": content_md,
            "content_images": content_images,
        }

    except Exception as e:
        print(f"    âŒ HTML ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
        return None


def run_migration(dry_run: bool = False, limit: int = None):
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
    print(f"\n{'='*60}")
    print("ğŸ“ ì½˜í…ì¸  Markdown ë§ˆì´ê·¸ë ˆì´ì…˜")
    print(f"   ëª¨ë“œ: {'DRY-RUN (ë¯¸ë¦¬ë³´ê¸°)' if dry_run else 'ì‹¤ì œ ì—…ë°ì´íŠ¸'}")
    if limit:
        print(f"   ì œí•œ: {limit}ê°œ")
    print(f"{'='*60}\n")

    # Supabase ì—°ê²°
    supabase = get_supabase_client()

    # ëª¨ë“  ê³µì§€ì‚¬í•­ source_url ê°€ì ¸ì˜¤ê¸°
    query = supabase.table("notices").select("id, title, source_url").order("published_at", desc=True)
    if limit:
        query = query.limit(limit)

    result = query.execute()
    notices = result.data or []

    print(f"ğŸ“‹ ëŒ€ìƒ ê³µì§€ì‚¬í•­: {len(notices)}ê°œ\n")

    if not notices:
        print("âš ï¸ ì—…ë°ì´íŠ¸í•  ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # HTTP ì„¸ì…˜ (í¬ë¡¤ëŸ¬ì™€ ë™ì¼í•œ í—¤ë”)
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept-Language': 'ko-KR,ko;q=0.9',
        'Referer': f'{BASE_URL}/',
    })

    success_count = 0
    skip_count = 0
    fail_count = 0

    for i, notice in enumerate(notices, 1):
        notice_id = notice['id']
        title = notice.get('title', '')[:40]
        source_url = notice.get('source_url')

        print(f"[{i}/{len(notices)}] {title}...")

        if not source_url:
            print(f"    â­ï¸ source_url ì—†ìŒ, ê±´ë„ˆëœ€")
            skip_count += 1
            continue

        # HTML ê°€ì ¸ì™€ì„œ Markdown ë³€í™˜
        converted = fetch_and_convert(source_url, session)

        if not converted:
            print(f"    âŒ ë³€í™˜ ì‹¤íŒ¨")
            fail_count += 1
            continue

        content_md = converted["content"]
        content_images = converted["content_images"]

        if dry_run:
            # ë¯¸ë¦¬ë³´ê¸°: ì²« 200ìë§Œ í‘œì‹œ
            preview = content_md[:200].replace('\n', '\\n')
            print(f"    âœ… ë³€í™˜ ì™„ë£Œ ({len(content_md)}ì, ì´ë¯¸ì§€ {len(content_images)}ê°œ)")
            print(f"    ğŸ“„ ë¯¸ë¦¬ë³´ê¸°: {preview}...")
        else:
            # ì‹¤ì œ DB ì—…ë°ì´íŠ¸
            try:
                update_data = {"content": content_md}
                if content_images:
                    update_data["content_images"] = content_images

                supabase.table("notices").update(update_data).eq("id", notice_id).execute()
                print(f"    âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ ({len(content_md)}ì, ì´ë¯¸ì§€ {len(content_images)}ê°œ)")
            except Exception as e:
                print(f"    âŒ DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
                fail_count += 1
                continue

        success_count += 1

        # ì„œë²„ ë¶€ë‹´ ë°©ì§€: 0.5~1ì´ˆ ëœë¤ ëŒ€ê¸°
        time.sleep(random.uniform(0.5, 1.0))

    # ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*60}")
    print(f"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
    print(f"   ì„±ê³µ: {success_count}ê°œ")
    print(f"   ê±´ë„ˆëœ€: {skip_count}ê°œ")
    print(f"   ì‹¤íŒ¨: {fail_count}ê°œ")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ì½˜í…ì¸  Markdown ë§ˆì´ê·¸ë ˆì´ì…˜")
    parser.add_argument("--dry-run", action="store_true", help="ì‹¤ì œ ì €ì¥ ì—†ì´ ë¯¸ë¦¬ë³´ê¸°")
    parser.add_argument("--limit", type=int, default=None, help="ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜")
    args = parser.parse_args()

    run_migration(dry_run=args.dry_run, limit=args.limit)
